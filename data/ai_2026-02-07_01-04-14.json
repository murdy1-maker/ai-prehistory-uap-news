[
  {
    "title": "Jeffs\u2019 Brands: KeepZone AI Announces Exclusive Agreement for the Reselling of Counter Underwater Systems for Drug Smuggling and Protecting Offshore Assets",
    "link": "https://www.manilatimes.net/2026/02/06/tmt-newswire/globenewswire/jeffs-brands-keepzone-ai-announces-exclusive-agreement-for-the-reselling-of-counter-underwater-systems-for-drug-smuggling-and-protecting-offshore-assets/2273303",
    "description": "Tel Aviv, Israel, Feb. 06, 2026 (GLOBE NEWSWIRE) -- Jeffs' Brands Ltd (\"Jeffs\u2019 Brands\u201d or the \"Company\u201d) (Nasdaq: JFBR, JFBRW), a data-driven e-commerce company operating on the Amazon Marketplace expanding into the global homeland security sector through advanced artificial intelligence (\"AI\u201d) -driven solutions, today announced that its wholly-owned subsidiary, KeepZone AI Inc. (\"KeepZone\"), has entered into an exclusive reseller agreement (the \"Agreement\u201d) with DSIT Solutions Ltd. (\"DSIT\u201d), a global leader in underwater domain awareness and acoustic intelligence solutions.KeepZone will help lead DSIT\u2019s entry into the Mexican market to counter underwater drug smuggling and protect offshore assets, as part of DSIT\u2019s strategic effort to support national authorities and critical infrastructure operators.Drug trafficking organizations are increasingly shifting their operations underwater, as maritime security above the surface continues to tighten. Much like terrorist organizations that adapt when defensive layers are reinforced, criminal cartels exploit the underwater domain, using covert diver operations, hull-mounted drug packages, and semi-submersible or fully submersible vessels to evade detection. DSIT\u2019s advanced underwater security systems are designed to counter this evolving threat by enabling early detection, classification, and response to covert underwater activity.Pursuant to the Agreement, KeepZone will lead the introduction of DSIT\u2019s advanced underwater security solutions to Mexican government agencies and energy operators, including systems for:Detection of hostile or unauthorized diversIdentification of unmanned underwater vehicles (\"UUVs\u201d)Protection of ports, anchorages, and coastal assetsUnderwater protection of offshore oil & gas platforms (\"Oil Rigs\u201d) against sabotage, smuggling, and covert underwater intrusionSupport for maritime drug intervention and counter-smuggling operations Together, KeepZone and DSIT may be able to support a truly multi-layered maritime security approach, above and below the waterline, with the potential to address a critical gap increasingly exploited by organized criminal networks.Alon Dayan, Chief Executive Officer of KeepZone, commented: \"By leading the deployment of DSIT\u2019s underwater security technologies in Mexico, we believe we are enabling authorities and offshore operators to detect and deter threats operating where traditional surveillance cannot, beneath the surface.\u201dAbout Jeffs\u2019 BrandsJeffs\u2019 Brands is a data-driven company that has recently pivoted into the global homeland security sector through its wholly-owned subsidiary, KeepZone AI Inc., following the entry into the definitive distribution agreement with Scanary Ltd., in December 2025. Jeffs\u2019 Brands aims to deliver comprehensive, multi-layered security ecosystems for critical infrastructure worldwide, capitalizing on the homeland security market\u2019s significant growth potential while leveraging its expertise in data-driven operations.For more information on Jeffs\u2019 Brands visit https://jeffsbrands.com.About DSIT Solutions Ltd.DSIT Solutions Ltd. specializes in underwater domain awareness, sonar, and acoustic intelligence systems designed to protect naval forces, critical maritime infrastructure, and offshore energy assets worldwide.Forward-Looking Statement DisclaimerThis press release contains \"forward-looking statements\u201d within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended, that are intended to be covered by the \"safe harbor\u201d created by those sections. Forward-looking statements, which are based on certain assumptions and describe the Company\u2019s future plans, strategies and expectations, can generally be identified by the use of forward-looking terms such as \"believe,\u201d \"expect,\u201d \"may,\u201d \"should,\u201d \"could,\u201d \"seek,\u201d \"intend,\u201d \"plan,\u201d \"goal,\u201d \"estimate,\u201d \"anticipate\u201d or other comparable terms. For example, the Company is using forward-looking statements when discussing the anticipated benefits of the Agreement, KeepZone\u2019s anticipated role in introducing DSIT\u2019s solutions to the Mexican market, the potential effectiveness of underwater security technologies, the ability of the KeepZone and DSIT to support national authorities and critical infrastructure operators, the potential ability of KeepZone and DSIT to support a multi-layered maritime security approach above and below the waterline, and the possibility that such an approach may help address security gaps that could be exploited by organized criminal networks. Because forward-looking statements relate to the future, they are subject to inherent uncertainties, risks and changes in circumstances that are difficult to predict and many of which are outside of the Company\u2019s control. The Company\u2019s actual results and financial condition may differ materially from those indicated in the forward-looking statements. Therefore, you should not rely on any of these forward-looking statements. Important factors that could cause the Company\u2019s actual results and financial condition to differ materially from those indicated in the forward-looking statements include, among others, the following: the Company\u2019s ability to adapt to significant future alterations in Amazon\u2019s policies; the Company\u2019s ability to sell its existing products and grow the Company\u2019s brands and product offerings; the Company\u2019s ability to meet its expectations regarding the revenue growth and the demand for e-commerce; the overall global economic environment; the impact of competition and new e-commerce technologies; general market, political and economic conditions in the countries in which the Company operates; projected capital expenditures and liquidity; the impact of possible changes in Amazon\u2019s policies and terms of use; the impact of the conditions in Israel; and the other risks and uncertainties described in the Company\u2019s Annual Report on Form 20-F for the year ended December 31, 2024, filed with the U.S. Securities and Exchange Commission (\"SEC\u201d), on March 31, 2025, and the Company\u2019s other filings with the SEC. The Company undertakes no obligation to publicly update any forward-looking statement, whether written or oral, that may be made from time to time, whether as a result of new information, future developments or otherwise.Investor Relations Contact:Michal EfratyAdi and Michal PR- IRInvestor Relations, Israelmichal@efraty.com",
    "source_id": "manilatimes",
    "pubDate": "2026-02-06 13:02:20"
  },
  {
    "title": "How to build AI employees that act more like employees and less like AI",
    "link": "https://www.cio.com/article/4128157/how-to-build-ai-employees-that-act-more-like-employees-and-less-like-ai.html",
    "description": "\u201cI want you to build an AI project manager.\u201dIt seemed like a simple request at the time; a fun little side project for one of our engineers to knock out in a couple of days between their \u201creal work.\u201dThat turned out to be partly right. It was a fun project, but it wasn\u2019t quick. It forced us to rethink almost everything we believed about agents. And somewhere along the way, it rewired our expectations for what AI in the enterprise can and should actually do.No one wants another chatbotThe first version of the AI project manager looked exactly like what the market was calling an AI agent.We wired up a language model. We gave it tools to read specs and scan tickets and wrapped it with a chat interface. We added retrieval over meeting transcripts, docs and decision logs.On paper, it was textbook agent architecture. In practice, it felt lacking.When we asked, it would summarize standups. It would write weekly status reports. It could scan our ticketing system and tell us what it found.The problem was: no one asked. It didn\u2019t fit into our standard workflow. We had to open our browser and go to the chat interface if we wanted to use it. We forgot it existed.I asked the team to make an effort to use the agent, but the more we used it, the more underwhelming it felt. It wasn\u2019t a real project manager. It couldn\u2019t organize tasks into bigger workstreams the way a project manager would. It didn\u2019t have the context to identify risks. It couldn\u2019t connect the dots to understand that the code we were delivering, the documentation that needed to be written and the marketing materials being prepared were all part of a bigger feature launch.We did what most agent developers do in that situation. We started providing more complex instructions in our prompt. When the agent got something wrong, we would update the prompt. Can\u2019t perform a task? Update the prompt. Give the user a bad answer? Update the prompt.And it helped. A little.Eventually, our prompt and instructions grew to contain a comprehensive archive of all the things the agent had ever done wrong. Because we were changing the prompts reactively, we would sometimes give the agent contradicting instructions. As our instructions became more complex, the agent\u2019s performance degraded. We realized that what we built was untenable and we needed to rethink the architecture.Conventional wisdom in this situation is to move to a multi-agent approach. Break up your big agent into several simpler ones. Make those agents work together. Bring in an observability solution to understand how the agent mesh is working as a whole.That didn\u2019t feel right to us. It felt like it wasn\u2019t addressing the core problem we were facing. We couldn\u2019t put our finger on exactly why. Then we had a key realization.What can employees do that agents can\u2019t?Instead of building an agent and trying to make it perform tasks through better instructions, we asked ourselves what we would do to onboard a new hire if we hired them for this role. As we started to explore this question, the team made an important observation. All of the onboarding for a human employee requires them to remember and learn.If we want our AI employee to perform more like a human, it needs to remember and learn, too. The problem was that this was uncharted territory in agent development. We couldn\u2019t just grab a framework to plug agent-learning capabilities into our project manager. No such framework existed. We were on our own.The first decision we made was to rebuild our agent in Slack. After all, that\u2019s how we would communicate with a human project manager, so that\u2019s how we wanted to communicate with our AI project manager. We gave it \u2014 him \u2014 a name and had Midjourney make us a photorealistic profile picture. With that, Jerri was born.Chris LatimerThat simple change made interacting with Jerri a lot more natural than going to our web-based chat interface. We set him up like we would any other team member. He could send direct messages. We added him to our project channels. We could tag him in conversations.We also rethought our agent data strategy from the ground up.Under the hoodChris LatimerJerri\u2019s architecture consists of five main components:An API layer for interacting with the agent and providing new information to it.A scheduler for recurring tasks.The core agent logic responsible for task execution.The long-term memory processing and storage.A set of agent tools that let Jerri integrate with external tools we use.Forming memoriesThe agent memory architecture we landed on was to separate memory processing out into two parts: raw memories and mental models. Raw memories represent the interactions and experiences Jerri has. Individual conversations, tool calls, documents and meeting transcripts were all considered raw memories. Mental models provide a way to capture the broader understanding of how memories fit together and allow Jerri to keep track of the bigger picture.Raw memories are formed in a variety of ways. Every time someone interacts with Jerri on Slack, it forms a memory. When Jerri tries to perform a task or receives a meeting transcript, it forms new memories. These memories get tagged and enriched with metadata. We use an LLM to identify and extract the people, places and things contained within a raw memory. This processing prepares the memories so that we can search and find the right memories when we need to use them.Onboarding JerriWe didn\u2019t want to start stuffing Jerri\u2019s prompt with instructions. Our goal was to provide as little information in the prompts as possible. We wanted a way for Jerri to learn and to get better at his job over time; to adapt his behavior based on feedback and experiences \u2014 more like a human.We didn\u2019t want to simply shuffle around the problem of updating prompts to our mental models. In other words, we didn\u2019t want to manually update the mental models every time Jerri made a mistake the way we would with prompts in the first version; we\u2019d be fighting the same antipattern we were trying to correct.At the same time, we needed some starting-point level of understanding to train Jerri on how we operated as a project team. For us, this was the equivalent of employee onboarding for our AI employee.We created baseline mental models for key subjects that we thought Jerri needed to understand. We defined initial mental models to understand the product we were working on, our software development lifecycle, team member capabilities and project priorities. We also gave Jerri a mental model of his specific roles and responsibilities. We defined his initial responsibilities as tracking launches and making sure we weren\u2019t forgetting important tasks.We imposed a constraint that mental models could only be updated by having Jerri process new information or by giving Jerri feedback and having Jerri update his mental models based on that. Jerri would have to learn on the job, just like the rest of us.Handling open-ended tasksWe didn\u2019t want Jerri to be a simple workflow automation. That is, we didn\u2019t want to preprogram Jerri with step-by-step instructions for how to complete individual tasks.When a team member tags Jerri in a Slack channel or through DM, they can make any request they want. Each message comes into Jerri\u2019s Slack webhook endpoint. This triggers the intent, plan and execution logic. Jerri uses an LLM to identify the user\u2019s intent. The planning module retrieves the relevant mental models related to the user\u2019s intention.Based on the current mental model for Jerri\u2019s roles and responsibilities, he can decide if he\u2019s equipped to handle the user\u2019s request. If so, the planner module creates a plan \u2014 usually a list of subtasks that Jerri needs to execute to achieve the immediate goal.Local session and state management are used as a short-term memory buffer to track task execution as Jerri tries to fulfill any requests that come in. Each interaction with the user, every plan for completing a task, every tool call and every task outcome get persisted as memories.These are important because they allow Jerri to do something most other agents can\u2019t: learn.Agent learningThere were two areas of learning we focused on most when building Jerri: task completion and feedback.Task completionAgents make mistakes. What they don\u2019t do today is learn from those mistakes. When Jerri attempts to complete a task, mistakes can take different forms.Jerri can misunderstand the task and do something different from what the user intendedJerri can complete the task, but in an inefficient wayJerri can declare victory on a task that has not been solvedMost of the time, Jerri completes tasks successfully. Jerri gets feedback three ways: failed task attempts, user responses to completed work and a slash command we built into Slack.Turning feedback into learningThe mechanism that drives learning is self-reflection.Using the task scheduler, we have Jerri wake up every few hours and check for new task failures. If it finds one, it will initiate the self-reflection process.Chris LatimerThis process looks for differences between any successful attempts and any failures. It performs a deep analysis on the available data, then makes adjustments to the applicable mental models.The next time Jerri receives a similar task, he has a more complete understanding of what worked and what didn\u2019t in previous attempts.Jerri\u2019s sick dayAI employees might not call in sick, but they are susceptible to outages like any other piece of software. It wasn\u2019t until Jerri stopped working that we realized how much we had come to rely on him.One of Jerri\u2019s scheduled jobs is to send us an agenda before our daily standup with any items the team needs to discuss. Before Jerri, we relied on a round-robin agenda where everyone talked about what they were going to do that day. Over time, we realized Jerri was doing a better job of focusing our discussions around key deliverables, risks and tasks. He would list specific questions for individual team members to answer.We\u2019d go over the list and discuss them as needed. Jerri would get the meeting transcript, update his mental models and take the new information into account. We found our meetings were more useful and productive than the standard go-around-the-room style standup.We all joined the call and went to pull up the agenda, but it wasn\u2019t there. The team had a laugh, realizing that we\u2019d slowly counted on Jerri to keep us on track. At that moment, I felt like we achieved the mission I had given the team several months before. We had built a real AI project manager.From chatbot to AI employeeToday, Jerri isn\u2019t perfect, but we\u2019ve come a long way from where we started. Jerri has moments where he sounds very LLM-like. He can be annoying when asking about tasks. But he\u2019s also a lot more capable at handling complex tasks and analysis.In many ways, we treat Jerri like an employee. We have Jerri perform self-assessments. We provide feedback. We set clear roles and responsibilities. We set expectations and we challenge him to exceed those expectations. Just like a real employee, sometimes he does and sometimes he falls short. Nobody\u2019s perfect. Not even AI.So what is the secret to building an AI employee that acts like an employee? Simple: Treat it like one.This article is published as part of the Foundry Expert Contributor Network.Want to join?",
    "source_id": "cio_africa",
    "pubDate": "2026-02-06 13:00:00"
  },
  {
    "title": "AI Agent Startup Decagon Triples Valuation To $4.5 Billion - Forbes",
    "link": "https://news.google.com/rss/articles/CBMiqgFBVV95cUxPcVo5T2xHWFo1bEJlQmFVdEhRMXlSLWZGR3dTOFNkZHdBNlVkUVNEWHA2eUpMcUwwZEVNQWRtajI4Q1RHTWVYcVlkZUpEX2lIeWNqMkROR3BfRU1yRjVfMzVGRjBET0NPVTVwTmFjRGtIU1NtbXZJbG5GOVRvTldXT201Vy1ZMnZUV29ZUXNMazVxcHVLd3lkaGJWREN5dTU5QUxkdHhoeHhGUQ?oc=5",
    "description": "AI Agent Startup Decagon Triples Valuation To $4.5 Billion Forbes",
    "source_id": "google",
    "pubDate": "2026-02-06 13:00:00"
  },
  {
    "title": "AI Companions For Seniors\u2014Can A Robot Really Keep Grandpa Company?",
    "link": "https://www.forbes.com/sites/rdaniel-foster/2026/02/06/ai-companions-for-seniors-can-a-robot-really-keep-grandpa-company/",
    "description": "AI companions promise conversation, reminders and engagement for lonely seniors\u2014but overreliance can pose emotional risks, and they can\u2019t replace human connection.",
    "source_id": "forbes",
    "pubDate": "2026-02-06 13:00:00"
  },
  {
    "title": "Qlik Joins Open Standard Push to End Data Chaos Across AI and Analytics",
    "link": "https://www.mychesco.com/a/news/regional/qlik-joins-open-standard-push-to-end-data-chaos-across-ai-and-analytics/",
    "description": "PHILADELPHIA, PA \u2014 Qlik announced it has joined the Open Semantic Interchange, an open source effort designed to bring order to fragmented enterprise data definitions as companies expand their use ...",
    "source_id": "mychesco",
    "pubDate": "2026-02-06 13:00:00"
  }
]