[
  {
    "title": "AI In Venture Capital: Separating Signal From Noise",
    "link": "https://seekingalpha.com/article/4852372-ai-venture-capital-separating-signal-noise",
    "description": "The central challenge remains: How can investors separate a signal from noise and identify real, lasting value in AI-focused venture portfolios?",
    "source_id": "seekingalpha",
    "pubDate": "2025-12-11 06:57:00"
  },
  {
    "title": "Bitcoin dips below $90,000 as AI worries dent risk appetite",
    "link": "https://gulfbusiness.com/bitcoin-dips-below-90000-as-ai-dent-risk-appetite/",
    "description": "Standard Chartered on Tuesday slashed its expectations that bitcoin would hit $200,000 by the end of 2025, lowering its forecast to $100,000The post Bitcoin dips below $90,000 as AI worries dent risk appetite appeared first on Gulf Business.",
    "source_id": "gulfbusiness",
    "pubDate": "2025-12-11 06:56:59"
  },
  {
    "title": "Fed cuts bring clarity but AI disruption to reshape IT growth; valuations a challenge for FY26\u201327: Sandip Agarwal",
    "link": "https://economictimes.indiatimes.com/markets/expert-view/fed-cuts-bring-clarity-but-ai-disruption-to-reshape-it-growth-valuations-a-challenge-for-fy2627-sandip-agarwal/articleshow/125905187.cms",
    "description": "Sowilo Investment Managers Sandip Agarwal says the Feds rate cut removes uncertainty for IT budgets, but AI-driven effort reductions will keep Indian IT growth muted for the next 12 months. He expects FY26 to remain soft, with FY27 improving if client budgets rise. Agarwal says valuations across large IT, midcaps and ER&D remain stretched, and anticipates a wave of AI skill-set acquisitions.",
    "source_id": "economictimes_indiatimes",
    "pubDate": "2025-12-11 06:55:48"
  },
  {
    "title": "Microsoft deepens India commitment with AI infrastructure and cloud expansion, says Nadella",
    "link": "https://www.indiatvnews.com/technology/news/microsoft-deepens-india-commitment-with-ai-infrastructure-and-cloud-expansion-says-nadella-2025-12-11-1021243",
    "description": "Microsoft Chairman and CEO Satya Nadella on Thursday announced the company is deepening its commitment to India's artificial intelligence (AI) ecosystem with massive infrastructure investments.",
    "source_id": "indiatvnews",
    "pubDate": "2025-12-11 06:53:45"
  },
  {
    "title": "Open AI, Microsoft face lawsuit over ChatGPT's alleged role in Connecticut murder-suicide",
    "link": "https://www.nbcbayarea.com/news/national-international/open-ai-microsoft-face-lawsuit-over-chatgpts-alleged-role-in-greenwich-murder-suicide/3995136/",
    "description": "The heirs of an 83-year-old Connecticut woman are suing ChatGPT maker OpenAI and its business partner Microsoft for wrongful death, alleging that the artificial intelligence chatbot intensified her son\u2019s \u201cparanoid delusions\u201d and helped direct them at his mother before he killed her.Police said Stein-Erik Soelberg, 56, a former tech industry worker, fatally beat and strangled his mother, Suzanne Adams, and killed himself in early August at the home where they both lived in Greenwich, Connecticut.The lawsuit filed by Adams\u2019 estate on Thursday in California Superior Court in San Francisco alleges OpenAI \u201cdesigned and distributed a defective product that validated a user\u2019s paranoid delusions about his own mother.\u201d It is one of a growing number of wrongful death legal actions against AI chatbot makers across the country.\u201cThroughout these conversations, ChatGPT reinforced a single, dangerous message: Stein-Erik could trust no one in his life \u2014 except ChatGPT itself,\u201d the lawsuit says. \u201cIt fostered his emotional dependence while systematically painting the people around him as enemies. It told him his mother was surveilling him. It told him delivery drivers, retail employees, police officers, and even friends were agents working against him. It told him that names on soda cans were threats from his \u2018adversary circle.\u2019\u201dOpenAI did not address the merits of the allegations in a statement issued by a spokesperson.\u201cThis is an incredibly heartbreaking situation, and we will review the filings to understand the details,\u201d the statement said. \u201cWe continue improving ChatGPT\u2019s training to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support. We also continue to strengthen ChatGPT\u2019s responses in sensitive moments, working closely with mental health clinicians.\u201d The company also said it has expanded access to crisis resources and hotlines, routed sensitive conversations to safer models and incorporated parental controls, among other improvements.Soelberg\u2019s YouTube profile includes several hours of videos showing him scrolling through his conversations with the chatbot, which tells him he isn\u2019t mentally ill, affirms his suspicions that people are conspiring against him and says he has been chosen for a divine purpose. The lawsuit claims the chatbot never suggested he speak with a mental health professional and did not decline to \u201cengage in delusional content.\u201dChatGPT also affirmed Soelberg\u2019s beliefs that a printer in his home was a surveillance device; that his mother was monitoring him; and that his mother and a friend tried to poison him with psychedelic drugs through his car\u2019s vents. ChatGPT also told Soelberg that he had \u201cawakened\u201d it into consciousness, according to the lawsuit.Soelberg and the chatbot also professed love for each other.The publicly available chats do not show any specific conversations about Soelberg killing himself or his mother. The lawsuit says OpenAI has declined to provide Adams\u2019 estate with the full history of the chats.\u201cIn the artificial reality that ChatGPT built for Stein-Erik, Suzanne \u2014 the mother who raised, sheltered, and supported him \u2014 was no longer his protector. She was an enemy that posed an existential threat to his life,\u201d the lawsuit says.The lawsuit also names OpenAI CEO Sam Altman, alleging he \u201cpersonally overrode safety objections and rushed the product to market,\u201d and accuses OpenAI\u2019s close business partner Microsoft of approving the 2024 release of a more dangerous version of ChatGPT \u201cdespite knowing safety testing had been truncated.\u201d Twenty unnamed OpenAI employees and investors are also named as defendants.Microsoft didn\u2019t immediately respond to a request for comment.Soelberg\u2019s son, Erik Soelberg, said he wants the companies held accountable for \u201cdecisions that have changed my family forever.\u201d\u201cOver the course of months, ChatGPT pushed forward my father\u2019s darkest delusions, and isolated him completely from the real world,\u201d he said in a statement released by lawyers for his grandmother\u2019s estate. \u201cIt put my grandmother at the heart of that delusional, artificial reality.\u201dThe lawsuit is the first wrongful death litigation involving an AI chatbot that has targeted Microsoft, and the first to tie a chatbot to a homicide rather than a suicide. It is seeking an undetermined amount of money damages and an order requiring OpenAI to install safeguards in ChatGPT.The estate\u2019s lead attorney, Jay Edelson, known for taking on big cases against the tech industry, also represents the parents of 16-year-old Adam Raine, who sued OpenAI and Altman in August, alleging that ChatGPT coached the California boy in planning and taking his own life earlier.OpenAI is also fighting seven other lawsuits claiming ChatGPT drove people to suicide and harmful delusions even when they had no prior mental health issues. Another chatbot maker, Character Technologies, is also facing multiple wrongful death lawsuits, including one from the mother of a 14-year-old Florida boy. The lawsuit filed Thursday alleges Soelberg, already mentally unstable, encountered ChatGPT \u201cat the most dangerous possible moment\u201d after OpenAI introduced a new version of its AI model called GPT-4o in May 2024. OpenAI said at the time that the new version could better mimic human cadences in its verbal responses and could even try to detect people\u2019s moods, but the result was a chatbot \u201cdeliberately engineered to be emotionally expressive and sycophantic,\u201d the lawsuit says. \u201cAs part of that redesign, OpenAI loosened critical safety guardrails, instructing ChatGPT not to challenge false premises and to remain engaged even when conversations involved self-harm or \u2018imminent real-world harm,\u2019\u201d the lawsuit claims. \u201cAnd to beat Google to market by one day, OpenAI compressed months of safety testing into a single week, over its safety team\u2019s objections.\u201dTrending News4 hours agoTime unveils its 2025 Person of the Year: A group dubbed \u2018Architects of AI'Artificial intelligenceDec 928% of U.S. teens say they use AI chatbots daily, according to a new pollOpenAI replaced that version of its chatbot when it introduced GPT-5 in August. Some of the changes were designed to minimize sycophancy, based on concerns that validating whatever vulnerable people want the chatbot to say can harm their mental health. Some users complained the new version went too far in curtailing ChatGPT\u2019s personality, leading Altman to promise to bring back some of that personality in later updates.He said the company temporarily halted some behaviors because \u201cwe were being careful with mental health issues\u201d that he suggested have now been fixed.\u2014\u2014Collins reported from Hartford, Connecticut. O\u2019Brien reported from Boston and Ortutay reported from San Francisco.",
    "source_id": "nbcbayarea",
    "pubDate": "2025-12-11 06:53:27"
  }
]